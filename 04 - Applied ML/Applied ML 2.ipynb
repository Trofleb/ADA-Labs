{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./CrowdstormingDataJuly1st.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import clean_data, group_data, prep_ML, normalize\n",
    "dfc = clean_data(df)\n",
    "dfg = group_data(dfc)\n",
    "X_p,y_possible = prep_ML(dfg)\n",
    "X = normalize(X_p, None)\n",
    "# We use our best version of the previous part.\n",
    "label_true = ((y_possible['rater1'] + y_possible['rater2']) / 2 <= 0.5).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's try the k-means algorithm with 2 clusters and print out the silhouette score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI: n_jobs = 1 because the parallel version of k-means doesn't work on OSX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2, max_iter=600, init=\"k-means++\", n_jobs=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = km.labels_\n",
    "s1 = metrics.silhouette_score(X, labels, metric='euclidean')\n",
    "print(\"s1 =\", s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_km(X):\n",
    "    km = KMeans(n_clusters=2, max_iter=600, init=\"k-means++\", n_jobs=1 )\n",
    "    km.fit(X)\n",
    "    labels = km.labels_\n",
    "    return metrics.silhouette_score(X, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the most valuable feature is the seIAT therefore we will remove it (just for fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import compute_feature_importance_rfc\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "# From previous exercice\n",
    "\n",
    "prop1 = np.sum(label_true) / len(label_true)\n",
    "prop0 = 1 - prop1\n",
    "class_weights = {\n",
    "    0 : prop0,\n",
    "    1 : prop1\n",
    "}\n",
    "\n",
    "best_results = {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 25}\n",
    "\n",
    "rfc = RFC(max_depth=best_results[\"max_depth\"], max_features=best_results[\"max_features\"], n_estimators=best_results[\"n_estimators\"], n_jobs=-1, class_weight=class_weights)\n",
    "compute_feature_importance_rfc(rfc, X, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = X.drop(\"seIAT\", axis=1)\n",
    "s2 = test_km(X2)\n",
    "print(\"s2 =\", s2)\n",
    "print(\"s2 - s1 =\", s2 - s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a better classification... that's fun !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now let's remove a second feature, we will follow the same intuition as before and remove the second best feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we know from before that the mean_Exp and goal information is at position 8, and 7 respectively in the X array\n",
    "X3 = X.drop([\"meanExp\", \"seIAT\"], axis=1)\n",
    "s3 = test_km(X3)\n",
    "print(\"s3 =\", s3)\n",
    "print(\"s3 - s1 =\", s3 - s1)\n",
    "print(\"s3 - s2 =\", s3 - s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even better improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we now remove seExp in addition to the other 2 (3rd best feature)\n",
    "X4 = X.drop([\"meanExp\", \"seExp\", \"seIAT\", \"meanIAT\"], axis=1)\n",
    "s4 = test_km(X4)\n",
    "print(\"s4 =\", s4)\n",
    "print(\"s4 - s1 =\", s4 - s1)\n",
    "print(\"s4 - s2 =\", s4 - s2)\n",
    "print(\"s4 - s3 =\", s4 - s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether the clustering is close to a dark/light separation we will compute in addition to the silhouette the adjusted mutual info score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2, max_iter=300, init=\"k-means++\", n_jobs=1 )\n",
    "\n",
    "def scoring_complete(X):\n",
    "    km.fit(X)\n",
    "    labels = km.labels_\n",
    "    print(\"silhouette score :\", metrics.silhouette_score(X, labels, metric='euclidean'))\n",
    "    print(\"closeness to true label score :\", metrics.adjusted_mutual_info_score(label_true, labels))\n",
    "\n",
    "scoring_complete(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scoring_complete(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that eventhough the silhouette score is better our label accuracy is the same as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoring_complete(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoring_complete(X4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's remove the worse features for example the red / yellow / redYellow / cards (not all are the absolute worst but they were all in the < 0.05 importance in the previous exercice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5 =  X.drop([\"yellowReds\", \"redCards\", \"yellowCards\"], axis=1)\n",
    "scoring_complete(X5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have good results ! the silhouette is better. And closeness is much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now remove all the features that have the worst feature importance until our closeness score drops significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc, X5, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X6 =  X5.drop([\"position\", \"leagueCountry\", \"height\"], axis=1)\n",
    "scoring_complete(X6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc,X6, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X7 =  X6.drop([\"defeats\"], axis=1)\n",
    "scoring_complete(X7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc, X7, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X8 =  X7.drop([\"weight\"], axis=1)\n",
    "scoring_complete(X8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc, X8, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X9 =  X8.drop([\"ties\"], axis=1)\n",
    "scoring_complete(X9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc, X9, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X10 =  X9.drop([\"goals\"], axis=1)\n",
    "scoring_complete(X10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc, X10, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X11 =  X10.drop([\"club\"], axis=1)\n",
    "scoring_complete(X11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc, X11, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X12 =  X11.drop([\"birthday\"], axis=1)\n",
    "scoring_complete(X12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(rfc, X12, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X13 =  X12.drop([\"victories\"], axis=1)\n",
    "scoring_complete(X13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing more gives worse results or equal results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
