{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./CrowdstormingDataJuly1st.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import clean_data, group_data, prep_ML, normalize\n",
    "dfc = clean_data(df)\n",
    "dfg = group_data(dfc)\n",
    "X_p,y_possible = prep_ML(dfg)\n",
    "X = normalize(X_p, None)\n",
    "# We use our best version of the previous part.\n",
    "label_true = ((y_possible['rater1'] + y_possible['rater2']) / 2 <= 0.5).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's try the k-means algorithm with 2 clusters and print out the silhouette score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI: n_jobs = 1 because the parallel version of k-means doesn't work on OSX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=2, max_iter=600, init=\"k-means++\", n_jobs=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = km.labels_\n",
    "s1 = metrics.silhouette_score(X, labels, metric='euclidean')\n",
    "print(\"s1 =\", s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_km(X):\n",
    "    km = KMeans(n_clusters=2, max_iter=600, init=\"k-means++\", n_jobs=1 )\n",
    "    km.fit(X)\n",
    "    labels = km.labels_\n",
    "    return metrics.silhouette_score(X, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the most valuable feature is the mean_Exp therefore we will remove it (just for fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import compute_feature_importance_rfc\n",
    "\n",
    "compute_feature_importance_rfc(X, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = X.drop(\"meanExp\", axis=1)\n",
    "s2 = test_km(X2)\n",
    "print(\"s2 =\", s2)\n",
    "print(\"s2 - s1 =\", s2 - s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a better result... that's fun !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now let's remove a second feature, we will follow the same intuition as before and remove the second best feature, the club information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we know from before that the mean_Exp and goal information is at position 8, and 7 respectively in the X array\n",
    "X3 = X.drop([\"meanExp\", \"goals\"], axis=1)\n",
    "s3 = test_km(X3)\n",
    "print(\"s3 =\", s3)\n",
    "print(\"s3 - s1 =\", s3 - s1)\n",
    "print(\"s3 - s2 =\", s3 - s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even better improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we now remove seExp in addition to the other 2 (3rd best feature)\n",
    "X4 = X.drop([\"meanExp\", \"goals\", \"seIAT\"], axis=1)\n",
    "s4 = test_km(X4)\n",
    "print(\"s4 =\", s4)\n",
    "print(\"s4 - s1 =\", s4 - s1)\n",
    "print(\"s4 - s2 =\", s4 - s2)\n",
    "print(\"s4 - s3 =\", s4 - s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether the clustering is close to a dark/light separation we will compute in addition to the silhouerre the accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scoring_complete(X):\n",
    "    km = KMeans(n_clusters=2, max_iter=300, init=\"k-means++\", n_jobs=1 )\n",
    "    km.fit(X)\n",
    "    labels = km.labels_\n",
    "    print(\"silhouette score :\", metrics.silhouette_score(X, labels, metric='euclidean'))\n",
    "    print(\"closeness to true label score :\", metrics.adjusted_mutual_info_score(label_true, labels))\n",
    "\n",
    "scoring_complete(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very low closeness score but at least it's positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoring_complete(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that eventhough the silhouette score is better our label accuracy is the same as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoring_complete(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoring_complete(X4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly here we are changinging the biais of the clustering algorithm (with respect to our \"true\" labels) **TODO : verify this !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's remove the worse features for example the red / yellow / redYellow / cards (not all are the absolute worst but they were all in the < 0.05 importance in the previous exercice.)\n",
    "\n",
    "rows : 8, 10, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X5 =  X.drop([\"yellowReds\", \"redCards\", \"yellowCards\"], axis=1)\n",
    "scoring_complete(X5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have good results ! the silhouette is good and closeness has improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now remove all the features that have the worst feature importance until our closeness score drops significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(X5, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X6 =  X.drop([\"yellowReds\", \"redCards\", \"yellowCards\", \"position\", \"leagueCountry\", \"height\"], axis=1)\n",
    "scoring_complete(X6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(X6, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X7 =  X.drop([\"yellowReds\", \"redCards\", \"yellowCards\", \"position\", \"leagueCountry\", \"height\", \"weight\"], axis=1)\n",
    "scoring_complete(X7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(X7, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X8 =  X.drop([\"yellowReds\", \"redCards\", \"yellowCards\", \"position\", \"leagueCountry\", \"height\", \"weight\", \"defeats\"], axis=1)\n",
    "scoring_complete(X8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compute_feature_importance_rfc(X8, label_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X9 =  X.drop([\"yellowReds\", \"redCards\", \"yellowCards\", \"position\", \"leagueCountry\", \"height\", \"weight\", \"defeats\", \"ties\"], axis=1)\n",
    "scoring_complete(X9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stop here as we have the worst result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X8[\"club\"], X8[\"meanExp\"], c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
